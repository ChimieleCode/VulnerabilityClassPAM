{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-21T10:45:54.310403Z",
     "end_time": "2024-05-21T10:46:03.322434Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Dict, Union, Iterable, Tuple\n",
    "from itertools import product\n",
    "\n",
    "from src.hazard import SecondOrderHazard, modify_hazard_curve\n",
    "from src.fragility import SimpleLogNormalFragility\n",
    "from src.vulnerability import VulnerabilityImplementation, VulnerabilityDamageState\n",
    "from src.loss_ratios import DegenerateLossRatio\n",
    "from src.loss_model import LossImplementation\n",
    "\n",
    "from src.utils import import_json"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEFINES USEFUL FUNCTIONS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defines the function to pass from probability in given years to MAFE:\n",
    "\n",
    "\\begin{equation}\n",
    "MAFE = - \\frac{ln(1 - p)}{T_R}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "- p is the probability of exceedence in a time window\n",
    "- $T_R$ is the time window\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_mafe_from_prob(probability: float, temporal_window: Union[float, int]) -> float:\n",
    "    \"\"\"Converts the probability of exceedence into the mean annual frequency\"\"\"\n",
    "    return - np.log(1 - probability)/temporal_window"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T10:46:03.322434Z",
     "end_time": "2024-05-21T10:46:03.339391Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define the first order hazard fitting**\n",
    "\n",
    "First order interpolation from Baker 2015 (DOI: 10.1193/021113EQS025M):\n",
    "\n",
    "\\begin{equation}\n",
    "H(s) = k_0 s^\\(-k_1\\)\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "-  k0, k1 are the fitting parameters\n",
    "-  s is the intensity measure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def mafe_first_order(im, k0, k1) -> float:\n",
    "    \"\"\"MAFE using first order approximation\"\"\"\n",
    "    return k0 * im ** -k1\n",
    "\n",
    "# I need to fit in log space\n",
    "def log_mafe_first_order(*args):\n",
    "    return np.log(mafe_first_order(*args))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T10:46:03.347109Z",
     "end_time": "2024-05-21T10:46:03.372758Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define the second order hazard fitting**\n",
    "\n",
    "Second order interpolation from Vamvatsikos 2013 (DOI: 10.1002/eqe.2265):\n",
    "\n",
    "\\begin{equation}\n",
    "H(s) = k_0 \\exp(-k_2 ln^2(s) - k_1 ln(s))\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "-  k0, k1, k2 are the fitting parameters\n",
    "-  s is the intensity measure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def mafe_second_order(im, k0, k1, k2) -> float:\n",
    "    \"\"\"MAFE using second order approximation\"\"\"\n",
    "    return k0 * np.exp(\n",
    "        -(\n",
    "                k1 * np.log(im)\n",
    "                + k2 * np.log(im)**2\n",
    "        )\n",
    "    )\n",
    "\n",
    "# I need to fit in log space\n",
    "def log_mafe_second_order(*args):\n",
    "    return np.log(mafe_second_order(*args))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T10:46:03.365168Z",
     "end_time": "2024-05-21T10:46:03.372758Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IMPORT DATA FROM THE INGV FILES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports and formats all the zones from INGV.\n",
    "\n",
    "Some zones are excluded because they do not define hazard values for probabilities different from 10% in 50 years"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'hazard\\\\INGV'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m probabilities_exc: List[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Each file refers to a different probability of exceedence for each zone\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# I need to initialize all the zones in the dictionary\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mINGV_FOLDER\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Loads the file\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     hazard_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(INGV_FOLDER \u001B[38;5;241m/\u001B[39m file, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mID\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# Adds the probability to the list\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'hazard\\\\INGV'"
     ]
    }
   ],
   "source": [
    "INGV_FOLDER: Path = Path('./hazard/INGV')\n",
    "\n",
    "hazard_curves: Dict[int, List[float]] = dict()\n",
    "probabilities_exc: List[float] = list()\n",
    "# Each file refers to a different probability of exceedence for each zone\n",
    "# I need to initialize all the zones in the dictionary\n",
    "for file in os.listdir(INGV_FOLDER):\n",
    "    # Loads the file\n",
    "    hazard_df = pd.read_csv(INGV_FOLDER / file, index_col='ID')\n",
    "    # Adds the probability to the list\n",
    "    probabilities_exc.append(int(file[3:5]))\n",
    "    for index in hazard_df.index:\n",
    "        # Checks if the id is already present in the dictionary\n",
    "        if index not in hazard_curves:\n",
    "            hazard_curves[index] = list()\n",
    "\n",
    "faulty_zones = set()\n",
    "# Collects the values from all files\n",
    "for file in os.listdir(INGV_FOLDER):\n",
    "    # Loads the file\n",
    "    hazard_df = pd.read_csv(INGV_FOLDER / file, index_col='ID')\n",
    "\n",
    "    for index in hazard_curves:\n",
    "        try:\n",
    "            intensity = hazard_df.loc[index]\n",
    "            # Adds the intensity measure to the hazard curves\n",
    "            hazard_curves[index].append(intensity['ag'])\n",
    "        except KeyError as e:\n",
    "            faulty_zones.add(index)\n",
    "\n",
    "# Delete faulty areas\n",
    "for faulty_index in faulty_zones:\n",
    "    del hazard_curves[faulty_index]\n",
    "\n",
    "# Turns the dictionary into a dataframe and adds the probabilities as indexes\n",
    "hazard_curves_df = pd.DataFrame(hazard_curves)\n",
    "hazard_curves_df['ID'] = probabilities_exc\n",
    "hazard_curves_df.set_index('ID', inplace=True)\n",
    "# Transpose to have the location ID as indexes\n",
    "transposed_hazard_curves_df = hazard_curves_df.T\n",
    "# Save\n",
    "transposed_hazard_curves_df.to_csv(Path('./hazard/hazard_curves/hazard_curves.csv'))\n",
    "\n",
    "print('Faulty IDs', faulty_zones)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-22T15:37:03.964707Z",
     "end_time": "2024-03-22T15:37:13.365215Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FITS HAZARD CURVES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each hazard curve in Italy, a second order hazard curve is fitted.\n",
    "\n",
    "From the fitting are excluded curves that have a zero value at any intensity.\n",
    "\n",
    "If the k2 parameter is found to be negative, a first order fitting is performed.\n",
    "\n",
    "Fot hte fitting, logarithmic least squares are used for the MAFE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit_hazard_curve(intensity_measures: Iterable,\n",
    "                     probabilities_of_exceedence: Iterable) -> Tuple[float, float, float] | None:\n",
    "    \"\"\"Fits the hazard curve\"\"\"\n",
    "    # Optional initial guess\n",
    "    k = [1e-6, 3, 0.1]  # Replace with your initial guess if available\n",
    "\n",
    "    # Perform curve fitting\n",
    "    try:\n",
    "        popt, pcov = curve_fit(\n",
    "            f=log_mafe_second_order,\n",
    "            xdata=intensity_measures,\n",
    "            ydata=np.log(probabilities_of_exceedence),\n",
    "            p0=k\n",
    "        )\n",
    "        # If the k2 parameters is negative, fit using first order\n",
    "        if popt[2] < 0:\n",
    "            popt, pcov = curve_fit(\n",
    "                f=log_mafe_first_order,\n",
    "                xdata=intensity_measures,\n",
    "                ydata=np.log(probabilities_of_exceedence),\n",
    "                p0=k[:2]\n",
    "            )\n",
    "            popt = list(popt) + [0.]\n",
    "\n",
    "        return tuple(popt)\n",
    "    except RuntimeError:\n",
    "        print('Runtime error')\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-22T15:37:13.383057Z",
     "end_time": "2024-03-22T15:37:13.464028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the saved file\n",
    "hazard_curves_df = pd.read_csv(Path('./hazard/hazard_curves/hazard_curves.csv'), index_col='Unnamed: 0')\n",
    "\n",
    "# Computes probability values\n",
    "mafe = [get_mafe_from_prob(int(key)/100, 50) for key in hazard_curves_df]\n",
    "\n",
    "# Instantiate the dictionary with the results of the fitting\n",
    "fitted_models = dict()\n",
    "excluded_models = set()\n",
    "for index, row in hazard_curves_df.iterrows():\n",
    "    # checks if there are zeros in the curve (given the values are in descending order I can check just the last one)\n",
    "    if row.iloc[-1] <= 1e-4:\n",
    "        # Skips where a zero is found\n",
    "        excluded_models.add(index)\n",
    "        continue\n",
    "    # Fit the curve\n",
    "    params = fit_hazard_curve(np.array(row), mafe)\n",
    "    # Check if fitting is successful\n",
    "    if params is not None:\n",
    "        fitted_models[index] = params\n",
    "    else:\n",
    "        excluded_models.add(index)\n",
    "\n",
    "fitted_values_df = pd.DataFrame(fitted_models)\n",
    "transposed_fitted_values_df = fitted_values_df.T\n",
    "transposed_fitted_values_df.to_csv(Path(f'./hazard/fitted_curves/hazard_fitted.csv'))\n",
    "\n",
    "print('Excluded Models', excluded_models)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-22T15:37:13.419625Z",
     "end_time": "2024-03-22T15:37:56.872940Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-22T15:37:56.878165Z",
     "end_time": "2024-03-22T15:37:56.957452Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
