{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:47.811858Z",
     "end_time": "2024-03-04T17:24:47.864715Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Dict, Tuple, Final\n",
    "from itertools import product\n",
    "\n",
    "from src.hazard import SecondOrderHazard, modify_hazard_curve\n",
    "from src.fragility import SimpleLogNormalFragility\n",
    "from src.vulnerability import VulnerabilityImplementation, VulnerabilityDamageState\n",
    "from src.loss_ratios import DegenerateLossRatio\n",
    "from src.loss_model import LossImplementation\n",
    "\n",
    "from src.utils import import_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HAZARD_CURVES_PATH: Path = Path('./hazard/fitted_curves/hazard_fitted.csv')\n",
    "FRAGILITY_MODELS_PATH: Path = Path('./dataset_fragility_curves/fragility_curves_RC.csv')\n",
    "\n",
    "DAMAGE_TO_LOSS_PATH: Path = Path('./input/damage_to_loss_model.json')\n",
    "\n",
    "# AMPLIFICATION OPTIONS\n",
    "SOIL: Literal['A', 'B', 'C', 'D', 'E'] = 'A'\n",
    "TOPOGRAPHIC: Literal['T1', 'T2', 'T3', 'T4'] = 'T1'\n",
    "\n",
    "# INTEGRATION OPTIONS\n",
    "MIN_MAF: float = 1e-6\n",
    "MAX_MAF: float = .1\n",
    "\n",
    "INTEGRATION_STEPS: int = 1000\n",
    "\n",
    "# Save Path\n",
    "SAVE_EAL_PATH: Path = Path(f'./losses/RC/losses_{SOIL}_{TOPOGRAPHIC}.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "SOIL_COEFFICIENT: Dict[str, float] = {\n",
    "    'A': 1,\n",
    "    'B': 1.15,\n",
    "    'C': None,\n",
    "    'D': None,\n",
    "    'E': None\n",
    "}\n",
    "\n",
    "# NTC2018 Tab. 3.2.V\n",
    "TOPOGRAPHIC_COEFFICIENT: Dict[str, float] = {\n",
    "    'T1': 1,\n",
    "    'T2': 1.2,\n",
    "    'T3': 1.2,\n",
    "    'T4': 1.4\n",
    " }\n",
    "\n",
    "AMP_COEFFICIENT: Final[float] = SOIL_COEFFICIENT[SOIL] * TOPOGRAPHIC_COEFFICIENT[TOPOGRAPHIC]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:47.829817Z",
     "end_time": "2024-03-04T17:24:47.949997Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import Hazard Models**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "hazard_curves_df = pd.read_csv(HAZARD_CURVES_PATH, index_col='Unnamed: 0')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:47.858735Z",
     "end_time": "2024-03-04T17:24:47.973931Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter out first order models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded Models {51203, 51204, 31237, 31238, 20487, 13833, 47634, 47635, 47636, 47637, 47638, 13847, 47639, 47640, 47641, 47642, 47643, 47646, 47647, 47648, 47649, 47650, 47651, 47652, 49183, 49184, 49185, 49186, 49187, 18481, 15410, 15411, 50738, 49205, 49206, 49207, 49208, 49209, 50739, 50740, 50760, 50761, 20042, 20043, 47194, 32347, 32348, 47195, 14946, 48739, 47204, 47205, 47206, 48740, 48741, 48742, 48743, 48744, 48745, 14963, 14964, 14965, 50293, 50294, 48760, 48761, 48762, 48763, 48764, 50295, 50296, 50316, 19597, 19598, 50317, 50318, 51853, 51854, 51855, 51856, 51865, 51866, 31903, 31904, 31905, 14500, 14501, 46760, 46761, 48296, 48297, 48298, 48299, 48300, 48301, 48302, 48303, 48304, 14515, 14516, 48312, 48313, 48314, 48315, 48316, 48317, 48318, 48319, 48320, 49849, 49850, 49851, 49852, 19151, 16080, 19152, 49872, 49873, 49874, 49875, 51407, 51408, 51424, 51425, 31459, 31460, 31461, 14055, 14056, 47855, 47856, 47857, 47858, 47859, 47860, 14069, 14070, 47861, 47862, 47863, 47864, 47865, 47866, 47867, 47868, 47869, 47870, 47871, 47872, 47873, 47874, 49404, 49405, 49406, 49407, 49408, 18704, 15633, 15634, 18705, 18706, 49428, 49429, 49430, 49431, 50961, 50962, 50963, 50981, 31014, 31015, 20264, 20265, 50982, 50983, 47414, 32567, 32568, 32569, 47415, 47416, 47417, 47418, 48961, 47426, 47427, 47428, 47429, 48962, 48963, 48964, 48965, 48966, 18258, 15187, 15188, 50516, 48982, 48983, 48984, 48985, 48986, 48987, 50517, 50518, 50538, 50539, 19820, 19821, 50540, 52078, 52079, 52080, 52081, 52082, 52083, 52084, 52085, 52086, 32125, 32126, 32127, 14722, 14723, 14724, 46982, 46983, 46984, 48518, 48519, 48520, 48521, 48522, 48523, 48524, 14739, 14740, 14741, 50071, 50072, 48537, 48538, 48539, 48540, 48541, 48542, 50073, 50074, 19374, 19375, 50094, 50095, 50096, 50097, 51630, 51631, 51632, 51644, 51645, 51646, 31681, 31682, 31683, 14278, 14279, 48075, 48076, 48077, 48078, 48079, 48080, 48081, 48082, 48083, 14292, 14293, 48084, 48085, 48086, 48087, 48088, 48089, 48090, 48091, 48092, 48093, 48094, 48095, 48096, 48097, 49627, 49628, 49629, 49630, 18928, 15857, 18929, 49650, 49651, 49652, 49653, 51184, 51185, 51186}\n"
     ]
    }
   ],
   "source": [
    "# Initialize hazard collection\n",
    "hazard_models: Dict[int, SecondOrderHazard] = dict()\n",
    "\n",
    "first_order_models = set()\n",
    "for index, row in hazard_curves_df.iterrows():\n",
    "    # Checks if the fitting was made using first order models by checking that k2 is not zero\n",
    "    if row.iloc[-1] <= 1e-6:\n",
    "        # Exclude the first order models\n",
    "        first_order_models.add(index)\n",
    "        continue\n",
    "    hazard_models[index] = modify_hazard_curve(SecondOrderHazard(*row), AMP_COEFFICIENT)\n",
    "\n",
    "print('Excluded Models', first_order_models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:47.893642Z",
     "end_time": "2024-03-04T17:24:48.773051Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import Loss Ratios**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "damage_to_loss_model_dct = import_json(DAMAGE_TO_LOSS_PATH)\n",
    "\n",
    "# Fist loss value represents DS0, we start form DS1\n",
    "loss_ratio_list = [\n",
    "    DegenerateLossRatio(val) for val in damage_to_loss_model_dct['LR'][1:]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:48.775047Z",
     "end_time": "2024-03-04T17:24:48.818961Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import Fragility Models**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "fragility_modes_df = pd.read_csv(FRAGILITY_MODELS_PATH, delimiter=';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:48.791002Z",
     "end_time": "2024-03-04T17:24:48.837889Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Defines Vulnerability Models**\n",
    "\n",
    "For each damage state, merge the loss ratio with the respective fragility model and defines the vulnerability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Instantiate the vulnerability collection\n",
    "vulnerability_models = dict()\n",
    "for _, row in fragility_modes_df.iterrows():\n",
    "    # Import for each DS just first row\n",
    "    frag_list: List[SimpleLogNormalFragility] = [\n",
    "        SimpleLogNormalFragility(\n",
    "            mu=row['mhu ' + ds + ' [g]'],\n",
    "            beta_=row['beta ' + ds + ' [-]']\n",
    "        )\n",
    "        for ds in ['DS1', 'DS2', 'DS3', 'DS4', 'DS5']\n",
    "    ]\n",
    "\n",
    "    vulnerability_model = VulnerabilityImplementation(\n",
    "        damage_states=[\n",
    "            VulnerabilityDamageState(frag, loss) for frag, loss in zip(frag_list, loss_ratio_list)\n",
    "        ]\n",
    "    )\n",
    "    # Defines the ID for each vulnerability model\n",
    "    building_type = f\"{row['Reference']} {row['Period']} {row['Code level']} {row['High']} {row['Infill']} {row['Vulnerability class']}\"\n",
    "    # Adds the vulnerability model to the collection\n",
    "    vulnerability_models[building_type] = vulnerability_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:48.826908Z",
     "end_time": "2024-03-04T17:24:48.886134Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COMPUTES THE EXPECTED ANNUAL LOSSES FOR EACH VULNERABILITY MODEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Every vulnerability model is integrated for each hazard model.\n",
    "\n",
    "Given that the second order interpolation might lead to a max MAFE value, the script checks whether the starting MAFE value is over the maximum allowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manfredi et al. pre-1970 GLD LR BF -\n",
      "Manfredi et al. pre-1970 GLD LR IF -\n",
      "Manfredi et al. pre-1970 GLD LR PF -\n",
      "Manfredi et al. pre-1970 GLD MR BF -\n",
      "Manfredi et al. pre-1970 GLD MR IF -\n",
      "Manfredi et al. pre-1970 GLD MR PF -\n",
      "Manfredi et al. pre-1970 GLD HR BF -\n",
      "Manfredi et al. pre-1970 GLD HR IF -\n",
      "Manfredi et al. pre-1970 GLD HR PF -\n",
      "Manfredi et al. 1970-1990 GLD LR BF -\n",
      "Manfredi et al. 1970-1990 GLD LR IF -\n",
      "Manfredi et al. 1970-1990 GLD LR PF -\n",
      "Manfredi et al. 1970-1990 GLD MR BF -\n",
      "Manfredi et al. 1970-1990 GLD MR IF -\n",
      "Manfredi et al. 1970-1990 GLD MR PF -\n",
      "Manfredi et al. 1970-1990 GLD HR BF -\n",
      "Manfredi et al. 1970-1990 GLD HR IF -\n",
      "Manfredi et al. 1970-1990 GLD HR PF -\n",
      "Manfredi et al. post-1991 GLD LR BF -\n",
      "Manfredi et al. post-1991 GLD LR IF -\n",
      "Manfredi et al. post-1991 GLD LR PF -\n",
      "Manfredi et al. post-1991 GLD MR BF -\n",
      "Manfredi et al. post-1991 GLD MR IF -\n",
      "Manfredi et al. post-1991 GLD MR PF -\n",
      "Manfredi et al. post-1991 GLD HR BF -\n",
      "Manfredi et al. post-1991 GLD HR IF -\n",
      "Manfredi et al. post-1991 GLD HR PF -\n",
      "Manfredi et al. pre-1970 ERD LR BF -\n",
      "Manfredi et al. pre-1970 ERD LR IF -\n",
      "Manfredi et al. pre-1970 ERD LR PF -\n",
      "Manfredi et al. pre-1970 ERD MR BF -\n",
      "Manfredi et al. pre-1970 ERD MR IF -\n",
      "Manfredi et al. pre-1970 ERD MR PF -\n",
      "Manfredi et al. pre-1970 ERD HR BF -\n",
      "Manfredi et al. pre-1970 ERD HR IF -\n",
      "Manfredi et al. pre-1970 ERD HR PF -\n",
      "Manfredi et al. 1970-1990 ERD LR BF -\n",
      "Manfredi et al. 1970-1990 ERD LR IF -\n",
      "Manfredi et al. 1970-1990 ERD LR PF -\n",
      "Manfredi et al. 1970-1990 ERD MR BF -\n",
      "Manfredi et al. 1970-1990 ERD MR IF -\n",
      "Manfredi et al. 1970-1990 ERD MR PF -\n",
      "Manfredi et al. 1970-1990 ERD HR BF -\n",
      "Manfredi et al. 1970-1990 ERD HR IF -\n",
      "Manfredi et al. 1970-1990 ERD HR PF -\n",
      "Manfredi et al. post-1991 ERD LR BF -\n",
      "Manfredi et al. post-1991 ERD LR IF -\n",
      "Manfredi et al. post-1991 ERD LR PF -\n",
      "Manfredi et al. post-1991 ERD MR BF -\n",
      "Manfredi et al. post-1991 ERD MR IF -\n",
      "Manfredi et al. post-1991 ERD MR PF -\n",
      "Manfredi et al. post-1991 ERD HR BF -\n",
      "Manfredi et al. post-1991 ERD HR IF -\n",
      "Manfredi et al. post-1991 ERD HR PF -\n",
      "Rosti et al. - GLD LR - -\n",
      "Rosti et al. - GLD MR - -\n",
      "Rosti et al. - GLD HR - -\n",
      "Rosti et al. pre-1981 ERD LR - -\n",
      "Rosti et al. pre-1981 ERD MR - -\n",
      "Rosti et al. pre-1981 ERD HR - -\n",
      "Rosti et al. post-1981 ERD LR - -\n",
      "Rosti et al. post-1981 ERD MR - -\n",
      "Rosti et al. post-1981 ERD HR - -\n",
      "Rosti et al. - - LR - C2\n",
      "Rosti et al. - - MR - C2\n",
      "Rosti et al. - - HR - C2\n",
      "Rosti et al. - - LR - D\n",
      "Rosti et al. - - MR - D\n",
      "Rosti et al. - - HR - D\n"
     ]
    }
   ],
   "source": [
    "# Dataframe with all the results\n",
    "eal_s = pd.DataFrame()\n",
    "\n",
    "# Saves the IDs of the hazard models\n",
    "eal_s['ID'] = [key for key in hazard_models]\n",
    "eal_s.set_index('ID', inplace=True)\n",
    "\n",
    "# Set containing hazard areas where integration failed\n",
    "strange_models = set()\n",
    "for vulnerability_id, vulnerability_model in vulnerability_models.items():\n",
    "    print(vulnerability_id)\n",
    "\n",
    "    # Initialize list of EALs for each vulnerability model\n",
    "    vul_eal_s = list()\n",
    "    for hazard_id, hazard_model in hazard_models.items():\n",
    "        # Finds the maximum allowed MAF for the hazard model (Remember, all second order models)\n",
    "        max_mafe = MAX_MAF\n",
    "        # Checks whether max_mafe is too large for the model, this avoids having to compute large numbers in some models\n",
    "        if hazard_model.k1**2 <= 4 * hazard_model.k2 * np.log(max_mafe / hazard_model.k0):\n",
    "            # If the max MAF is lower than the default one, changes the initial MAF\n",
    "            # .99 is used to avoid rounding errors\n",
    "            max_mafe = hazard_model.max_probability * .99\n",
    "\n",
    "        # Instantiate loss model\n",
    "        loss_model = LossImplementation(vulnerability=vulnerability_model, hazard=hazard_model)\n",
    "\n",
    "        # Computes EALs 1000 steps stopping at MAF 1e-6. This might fail if hazard k2<0\n",
    "        eal = loss_model.expected_annual_loss(MIN_MAF, max_mafe, steps=INTEGRATION_STEPS)\n",
    "\n",
    "        # Checks for failed values\n",
    "        if isinstance(eal, float) and pd.isna(eal):\n",
    "            strange_models.add(hazard_id)\n",
    "            print('Failed:', hazard_id, vulnerability_id)\n",
    "            eal = None\n",
    "\n",
    "        # Adds the value to the list\n",
    "        vul_eal_s.append(eal)\n",
    "\n",
    "    # Adds EALs to the dataframe\n",
    "    eal_s[vulnerability_id] = vul_eal_s"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:24:48.860168Z",
     "end_time": "2024-03-04T17:55:18.862145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "eal_s.to_csv(SAVE_EAL_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:55:18.931658Z",
     "end_time": "2024-03-04T17:55:20.947685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Models: set()\n"
     ]
    }
   ],
   "source": [
    "print('Failed Models:', strange_models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:55:20.953665Z",
     "end_time": "2024-03-04T17:55:20.959649Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
