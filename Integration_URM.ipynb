{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:43.244991Z",
     "end_time": "2024-03-05T10:49:50.549963Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Dict, Tuple\n",
    "from itertools import product\n",
    "\n",
    "from src.hazard import SecondOrderHazard, modify_hazard_curve\n",
    "from src.fragility import SimpleLogNormalFragility\n",
    "from src.vulnerability import VulnerabilityImplementation, VulnerabilityDamageState\n",
    "from src.loss_ratios import DegenerateLossRatio\n",
    "from src.loss_model import LossImplementation\n",
    "\n",
    "from src.utils import import_json"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "OPTIONS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "HAZARD_CURVES_PATH: Path = Path('./hazard/fitted_curves/hazard_fitted.csv')\n",
    "FRAGILITY_MODELS_PATH: Path = Path('./dataset_fragility_curves/fragility_curves_URM.csv')\n",
    "\n",
    "DAMAGE_TO_LOSS_PATH: Path = Path('./input/damage_to_loss_model.json')\n",
    "\n",
    "# AMPLIFICATION OPTIONS\n",
    "SOIL: Literal['A', 'B', 'C', 'D', 'E'] = 'A'\n",
    "TOPOGRAPHIC: Literal['T1', 'T2', 'T3', 'T4'] = 'T1'\n",
    "\n",
    "# INTEGRATION OPTIONS\n",
    "MIN_MAF: float = 1e-6\n",
    "MAX_MAF: float = .1\n",
    "\n",
    "INTEGRATION_STEPS: int = 1000\n",
    "\n",
    "# Save Path\n",
    "SAVE_EAL_PATH: Path = Path(f'./losses/URM/losses_{SOIL}_{TOPOGRAPHIC}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:50.551941Z",
     "end_time": "2024-03-05T10:49:50.562911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SOIL_COEFFICIENT: Dict[str, float] = {\n",
    "    'A': 1,\n",
    "    'B': 1.15,\n",
    "    'C': None,\n",
    "    'D': None,\n",
    "    'E': None\n",
    "}\n",
    "\n",
    "TOPOGRAPHIC_COEFFICIENT: Dict[str, float] = {\n",
    "    'T1': 1,\n",
    "    'T2': None,\n",
    "    'T3': None,\n",
    "    'T4': None\n",
    " }\n",
    "\n",
    "AMP_COEFFICIENT: float = SOIL_COEFFICIENT[SOIL] * TOPOGRAPHIC_COEFFICIENT[TOPOGRAPHIC]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:50.564906Z",
     "end_time": "2024-03-05T10:49:50.592557Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import Hazard Models**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "hazard_curves_df = pd.read_csv(HAZARD_CURVES_PATH, index_col='Unnamed: 0')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:50.584584Z",
     "end_time": "2024-03-05T10:49:50.635456Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter out first order models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded Models {51203, 51204, 31237, 31238, 20487, 13833, 47634, 47635, 47636, 47637, 47638, 13847, 47639, 47640, 47641, 47642, 47643, 47646, 47647, 47648, 47649, 47650, 47651, 47652, 49183, 49184, 49185, 49186, 49187, 18481, 15410, 15411, 50738, 49205, 49206, 49207, 49208, 49209, 50739, 50740, 50760, 50761, 20042, 20043, 47194, 32347, 32348, 47195, 14946, 48739, 47204, 47205, 47206, 48740, 48741, 48742, 48743, 48744, 48745, 14963, 14964, 14965, 50293, 50294, 48760, 48761, 48762, 48763, 48764, 50295, 50296, 50316, 19597, 19598, 50317, 50318, 51853, 51854, 51855, 51856, 51865, 51866, 31903, 31904, 31905, 14500, 14501, 46760, 46761, 48296, 48297, 48298, 48299, 48300, 48301, 48302, 48303, 48304, 14515, 14516, 48312, 48313, 48314, 48315, 48316, 48317, 48318, 48319, 48320, 49849, 49850, 49851, 49852, 19151, 16080, 19152, 49872, 49873, 49874, 49875, 51407, 51408, 51424, 51425, 31459, 31460, 31461, 14055, 14056, 47855, 47856, 47857, 47858, 47859, 47860, 14069, 14070, 47861, 47862, 47863, 47864, 47865, 47866, 47867, 47868, 47869, 47870, 47871, 47872, 47873, 47874, 49404, 49405, 49406, 49407, 49408, 18704, 15633, 15634, 18705, 18706, 49428, 49429, 49430, 49431, 50961, 50962, 50963, 50981, 31014, 31015, 20264, 20265, 50982, 50983, 47414, 32567, 32568, 32569, 47415, 47416, 47417, 47418, 48961, 47426, 47427, 47428, 47429, 48962, 48963, 48964, 48965, 48966, 18258, 15187, 15188, 50516, 48982, 48983, 48984, 48985, 48986, 48987, 50517, 50518, 50538, 50539, 19820, 19821, 50540, 52078, 52079, 52080, 52081, 52082, 52083, 52084, 52085, 52086, 32125, 32126, 32127, 14722, 14723, 14724, 46982, 46983, 46984, 48518, 48519, 48520, 48521, 48522, 48523, 48524, 14739, 14740, 14741, 50071, 50072, 48537, 48538, 48539, 48540, 48541, 48542, 50073, 50074, 19374, 19375, 50094, 50095, 50096, 50097, 51630, 51631, 51632, 51644, 51645, 51646, 31681, 31682, 31683, 14278, 14279, 48075, 48076, 48077, 48078, 48079, 48080, 48081, 48082, 48083, 14292, 14293, 48084, 48085, 48086, 48087, 48088, 48089, 48090, 48091, 48092, 48093, 48094, 48095, 48096, 48097, 49627, 49628, 49629, 49630, 18928, 15857, 18929, 49650, 49651, 49652, 49653, 51184, 51185, 51186}\n"
     ]
    }
   ],
   "source": [
    "# Initialize hazard collection\n",
    "hazard_models: Dict[int, SecondOrderHazard] = dict()\n",
    "\n",
    "first_order_models = set()\n",
    "for index, row in hazard_curves_df.iterrows():\n",
    "    # Checks if the fitting was made using first order models by checking that k2 is not zero\n",
    "    if row.iloc[-1] <= 1e-6:\n",
    "        # Exclude the first order models\n",
    "        first_order_models.add(index)\n",
    "        continue\n",
    "    hazard_models[index] = modify_hazard_curve(SecondOrderHazard(*row), AMP_COEFFICIENT)\n",
    "\n",
    "print('Excluded Models', first_order_models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:50.637464Z",
     "end_time": "2024-03-05T10:49:51.554945Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import Loss Ratios**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "damage_to_loss_model_dct = import_json(DAMAGE_TO_LOSS_PATH)\n",
    "\n",
    "# Fist loss value represents DS0, we start form DS1\n",
    "loss_ratio_list = [\n",
    "    DegenerateLossRatio(val) for val in damage_to_loss_model_dct['LR'][1:]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:51.559647Z",
     "end_time": "2024-03-05T10:49:51.574168Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import Fragility Models**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "fragility_modes_df = pd.read_csv(FRAGILITY_MODELS_PATH, delimiter=';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:51.575150Z",
     "end_time": "2024-03-05T10:49:51.612062Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Defines Vulnerability Models**\n",
    "\n",
    "For each damage state, merge the loss ratio with the respective fragility model and defines the vulnerability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Instantiate the vulnerability collection\n",
    "vulnerability_models = dict()\n",
    "for _, row in fragility_modes_df.iterrows():\n",
    "    # Import for each DS just first row\n",
    "    frag_list: List[SimpleLogNormalFragility] = [\n",
    "        SimpleLogNormalFragility(\n",
    "            mu=row['mhu ' + ds + ' [g]'],\n",
    "            beta_=row['beta ' + ds + ' [-]']\n",
    "        )\n",
    "        for ds in ['DS1', 'DS2', 'DS3', 'DS4', 'DS5']\n",
    "    ]\n",
    "\n",
    "    vulnerability_model = VulnerabilityImplementation(\n",
    "        damage_states=[\n",
    "            VulnerabilityDamageState(frag, loss) for frag, loss in zip(frag_list, loss_ratio_list)\n",
    "        ]\n",
    "    )\n",
    "    # Defines the ID for each vulnerability model\n",
    "    building_type = f\"{row['Reference']} {row['Period']} {row['Code level']} {row['High']} {row['Vulnerability class']}\"\n",
    "    # Adds the vulnerability model to the collection\n",
    "    vulnerability_models[building_type] = vulnerability_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:51.600082Z",
     "end_time": "2024-03-05T10:49:51.613047Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COMPUTES THE EXPECTED ANNUAL LOSSES FOR EACH VULNERABILITY MODEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Every vulnerability model is integrated for each hazard model.\n",
    "\n",
    "Given that the second order interpolation might lead to a max MAFE value, the script checks whether the starting MAFE value is over the maximum allowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donà et al. - - - A\n",
      "Donà et al. - - - B\n",
      "Donà et al. - - - C\n",
      "Donà et al. - - - D\n",
      "Donà et al. - - - E\n",
      "Donà et al. - - - F\n",
      "Donà et al. Pre-1919 - MR -\n",
      "Donà et al. Pre-1919 - LR -\n",
      "Donà et al. 1919–1945 - MR -\n",
      "Donà et al. 1919–1945 - LR -\n",
      "Donà et al. 1946–1960 - MR -\n",
      "Donà et al. 1946–1960 - LR -\n",
      "Donà et al. 1961–1980 - MR -\n",
      "Donà et al. 1961–1980 - LR -\n",
      "Donà et al. Post-1980 - MR -\n",
      "Donà et al. Post-1980 - LR -\n",
      "Lagomarsino et al. - - - A\n",
      "Lagomarsino et al. - - - B\n",
      "Lagomarsino et al. - - - C\n",
      "Lagomarsino et al. - - - D\n",
      "Rosti et al. < 1919 - LH -\n",
      "Rosti et al. < 1919 - MH -\n",
      "Rosti et al. 1919-1945 - LH -\n",
      "Rosti et al. 1919-1945 - MH -\n",
      "Rosti et al. 1946-1961 - LH -\n",
      "Rosti et al. 1946-1961 - MH -\n",
      "Rosti et al. 1962-1971 - LH -\n",
      "Rosti et al. 1962-1971 - MH -\n",
      "Rosti et al. 1972-1981 - LH -\n",
      "Rosti et al. 1972-1981 - MH -\n",
      "Rosti et al. > 1981 - LH -\n",
      "Rosti et al. > 1981 - MH -\n",
      "Rosti et al. - - LH A\n",
      "Rosti et al. - - MH A\n",
      "Rosti et al. - - LH B\n",
      "Rosti et al. - - MH B\n",
      "Rosti et al. - - LH C1\n",
      "Rosti et al. - - MH C1\n",
      "Zuccaro et al. - - - A\n",
      "Zuccaro et al. - - - B\n",
      "Zuccaro et al. - - - C\n"
     ]
    }
   ],
   "source": [
    "# Dataframe with all the results\n",
    "eal_s = pd.DataFrame()\n",
    "\n",
    "# Saves the IDs of the hazard models\n",
    "eal_s['ID'] = [key for key in hazard_models]\n",
    "eal_s.set_index('ID', inplace=True)\n",
    "\n",
    "# Set containing hazard areas where integration failed\n",
    "strange_models = set()\n",
    "for vulnerability_id, vulnerability_model in vulnerability_models.items():\n",
    "    print(vulnerability_id)\n",
    "\n",
    "    # Initialize list of EALs for each vulnerability model\n",
    "    vul_eal_s = list()\n",
    "    for hazard_id, hazard_model in hazard_models.items():\n",
    "        # Finds the maximum allowed MAF for the hazard model (Remember, all second order models)\n",
    "        max_mafe = MAX_MAF\n",
    "        # Checks whether max_mafe is too large for the model, this avoids having to compute large numbers in some models\n",
    "        if hazard_model.k1**2 <= 4 * hazard_model.k2 * np.log(max_mafe / hazard_model.k0):\n",
    "            # If the max MAF is lower than the default one, changes the initial MAF\n",
    "            # .99 is used to avoid rounding errors\n",
    "            max_mafe = hazard_model.max_probability * .99\n",
    "\n",
    "        # Instantiate loss model\n",
    "        loss_model = LossImplementation(vulnerability=vulnerability_model, hazard=hazard_model)\n",
    "\n",
    "        # Computes EALs 1000 steps stopping at MAF 1e-6. This might fail if hazard k2<0\n",
    "        eal = loss_model.expected_annual_loss(MIN_MAF, max_mafe, steps=INTEGRATION_STEPS)\n",
    "\n",
    "        # Checks for failed values\n",
    "        if isinstance(eal, float) and pd.isna(eal):\n",
    "            strange_models.add(hazard_id)\n",
    "            print('Failed:', hazard_id, vulnerability_id)\n",
    "            eal = None\n",
    "\n",
    "        # Adds the value to the list\n",
    "        vul_eal_s.append(eal)\n",
    "\n",
    "    # Adds EALs to the dataframe\n",
    "    eal_s[vulnerability_id] = vul_eal_s"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T10:49:51.618035Z",
     "end_time": "2024-03-05T11:09:08.494069Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "eal_s.to_csv(SAVE_EAL_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T11:09:08.552519Z",
     "end_time": "2024-03-05T11:09:09.754488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Models: set()\n"
     ]
    }
   ],
   "source": [
    "print('Failed Models:', strange_models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T11:09:09.759475Z",
     "end_time": "2024-03-05T11:09:09.763501Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
